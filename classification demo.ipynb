{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification,AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\Siri\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01200723648071289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ed2a202a2949939cc829d4460e4f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\",\n",
    "}\n",
    " \n",
    "K = len(labels)\n",
    "\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 4\n",
    "lr_init = 5e-5\n",
    "max_len = 256\n",
    "warmup_steps = 3\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data: pd.DataFrame, bsize: int) -> List[Tuple[BatchEncoding, List[int], List[str]]]:\n",
    "    lst = []\n",
    "    l = len(data)//bsize\n",
    "    for i in range(l):\n",
    "        batch_text = data['text'][bsize*i:bsize*(i+1)].tolist()\n",
    "        X = tokenizer.batch_encode_plus(batch_text, truncation =True, padding= 'max_length',max_length = max_len, add_special_tokens=True, return_tensors='pt')\n",
    "        Y = torch.LongTensor(data['label'][bsize*i:bsize*(i+1)].tolist())\n",
    "        s = batch_text\n",
    "        lst.append((X,Y,s))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset\n",
    "df_train = dataset['train'].to_pandas().sample(frac=1).reset_index(drop=True)[:40]\n",
    "df_test = dataset['test'].to_pandas().sample(frac=1).reset_index(drop=True)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = batch_data(df_train, bsize=batch_size)\n",
    "test_batches = batch_data(df_test, bsize=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Siri\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transformer model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=K, output_hidden_states=True)\n",
    "\n",
    "# The torch `device` on which to execute the model computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # GPU\n",
    "else:\n",
    "    device = torch.device('cpu') # CPU\n",
    "model.to(device)\n",
    "\n",
    "# The gradient descent optimizer used for fine tuning\n",
    "optimizer = AdamW(model.parameters(), lr=lr_init)\n",
    "\n",
    "# The gradient descent learning rate\n",
    "lr = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, \n",
    "    num_training_steps=len(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def runner(batches, train=True):\n",
    "    if train == True:\n",
    "        # train loop\n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            progress_bar = tqdm(range(len(batches))) # add tqdm bar\n",
    "            a = load_metric(\"accuracy\") # load accuracy metric\n",
    "            prediction = []\n",
    "            acc = []\n",
    "            loss_lst = []\n",
    "            \n",
    "\n",
    "            for item in batches:\n",
    "                # get each batch from batches\n",
    "                batch = {'input_ids':torch.as_tensor(item[0]['input_ids'], device=device),\n",
    "                         'attention_mask':torch.as_tensor(item[0]['attention_mask'], device=device),\n",
    "                         'labels': torch.as_tensor(item[1], device=device)}\n",
    "                \n",
    "                with torch.enable_grad():\n",
    "                    \n",
    "                    # if train is true, so this gradient descent process\n",
    "                    outputs = model(**batch)\n",
    "                    loss = outputs.loss\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    lr.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    progress_bar.update(1) # update progree bar\n",
    "                \n",
    "                # add the model outputs to corresponding results list\n",
    "                predict_label = torch.argmax(outputs.logits, dim=1) # get the label with the maximum probability\n",
    "                prediction.append(predict_label)\n",
    "                loss_lst.append(loss)\n",
    "                acc.append(a.compute(predictions = predict_label, references = item[1])['accuracy'])\n",
    "           \n",
    "            # compute mean metrics computed over data in batches\n",
    "            mean_loss = float(sum(loss_lst)/len(loss_lst))\n",
    "            mean_accuracy = sum(acc)/len(acc)\n",
    "\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # testing loop\n",
    "        model.eval()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            progress_bar = tqdm(range(len(batches))) # add tqdm bar\n",
    "            a = load_metric(\"accuracy\") # load accuracy metric\n",
    "            prediction = []\n",
    "            acc = []\n",
    "            loss_lst = []\n",
    "            \n",
    "\n",
    "            for item in batches:\n",
    "                # get each batch from batches\n",
    "                batch = {'input_ids':torch.as_tensor(item[0]['input_ids'], device=device),\n",
    "                         'attention_mask':torch.as_tensor(item[0]['attention_mask'], device=device),\n",
    "                         'labels': torch.as_tensor(item[1], device=device)}\n",
    "                \n",
    "                # if train is not true, just get the results from the current model\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch)\n",
    "                    \n",
    "                    # update progree bar\n",
    "                    progress_bar.update(1)\n",
    "                \n",
    "                # add the model outputs to corresponding results list\n",
    "                predict_label = torch.argmax(outputs.logits, dim=1) # get the label with the maximum probability\n",
    "                prediction.append(predict_label)\n",
    "                loss_lst.append(outputs.loss)\n",
    "                acc.append(a.compute(predictions = predict_label, references = item[1])['accuracy'])\n",
    "            \n",
    "            # compute mean metrics computed over data in batches\n",
    "            mean_loss = float(sum(loss_lst)/len(loss_lst))\n",
    "            mean_accuracy = sum(acc)/len(acc)\n",
    "            \n",
    "        \n",
    "    return (prediction,mean_loss, mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01200723648071289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dde3e1232a403cb3190f9dc9ec8941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011080741882324219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a05ac396404d61930702a102c021e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011597156524658203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff08bc7ceb824e5a9742cbd0dc4f500f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012984275817871094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a76d62d68d43288dd14288b8c29dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013124465942382812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0049d6d6d67d4fb3ac1430789bde3f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = runner(train_batches, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Set:\n",
      "loss: 1.2863134145736694\n",
      "accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "print('Traning Set:')\n",
    "\n",
    "print('loss:',train_results[1])\n",
    "print('accuracy:',train_results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012164831161499023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617b8c42be7040daa26925668ae34875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011461973190307617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed8b01c176e41e69df8989e1a0c885a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011008262634277344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ae227fee5c45fab5b3b53c6d3aae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013164043426513672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a939dd576d4c8580b0ee469c308107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014061927795410156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d11d3c6e8444cc7a61b77648ff7614a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = runner(test_batches, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set:\n",
      "loss: 1.3811625242233276\n",
      "accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "print('Testing Set:')\n",
    "\n",
    "print('loss:',test_results[1])\n",
    "print('accuracy:',test_results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANLY590",
   "language": "python",
   "name": "anly590"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
